{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197dda09",
   "metadata": {},
   "source": [
    "# Cell 1: Descriptive Statistics\n",
    "In this cell, we will cover basic descriptive statistics including mean, median, mode, standard deviation, and variance.\n",
    "\n",
    "**Mean:** The average of all the numbers in the dataset. It is calculated by summing all the values and dividing by the count of values.\n",
    "\n",
    "**Median:** The middle value of the dataset when the numbers are sorted in ascending order. If the count of numbers is even, the median is the average of the two middle numbers.\n",
    "\n",
    "**Mode:** The most frequently occurring value in the dataset. A dataset can have more than one mode if multiple values have the highest frequency.\n",
    "\n",
    "**Standard Deviation:** A measure of the amount of variation or dispersion in a set of values. A low standard deviation indicates that the values tend to be close to the mean, while a high standard deviation indicates that the values are spread out over a wider range.\n",
    "\n",
    "**Variance:** The average of the squared differences from the mean. It is the square of the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98501018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'Scores': [88, 92, 79, 93, 85, 91, 87, 94, 78, 81]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculating Mean\n",
    "mean = df['Scores'].mean()\n",
    "print(f'Mean: {mean}')\n",
    "\n",
    "# Calculating Median\n",
    "median = df['Scores'].median()\n",
    "print(f'Median: {median}')\n",
    "\n",
    "# Calculating Mode\n",
    "mode = df['Scores'].mode()[0]\n",
    "print(f'Mode: {mode}')\n",
    "\n",
    "# Calculating Standard Deviation\n",
    "std_dev = df['Scores'].std()\n",
    "print(f'Standard Deviation: {std_dev}')\n",
    "\n",
    "# Calculating Variance\n",
    "variance = df['Scores'].var()\n",
    "print(f'Variance: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da82c0",
   "metadata": {},
   "source": [
    "# Cell 2: Probability Distributions\n",
    "In this cell, we will cover some common probability distributions such as normal distribution and binomial distribution.\n",
    "\n",
    "**Normal Distribution:** A continuous probability distribution that is symmetrical around its mean, meaning that it has a bell-shaped curve. It is characterized by its mean and standard deviation.\n",
    "\n",
    "**Binomial Distribution:** A discrete probability distribution that models the number of successes in a fixed number of trials, each with the same probability of success. It is characterized by the number of trials (n) and the probability of success (p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49feabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, binom\n",
    "\n",
    "# Normal Distribution\n",
    "mean, std_dev = 0, 1\n",
    "x = np.linspace(-3, 3, 100)\n",
    "pdf = norm.pdf(x, mean, std_dev)\n",
    "print('Normal Distribution PDF:')\n",
    "print(pdf)\n",
    "\n",
    "# Binomial Distribution\n",
    "n, p = 10, 0.5\n",
    "binom_dist = binom(n, p)\n",
    "x = np.arange(0, 11)\n",
    "pmf = binom_dist.pmf(x)\n",
    "print('\\nBinomial Distribution PMF:')\n",
    "print(pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d13f1",
   "metadata": {},
   "source": [
    "# Cell 3: Hypothesis Testing\n",
    "In this cell, we will cover the basics of hypothesis testing, including null and alternative hypotheses, p-values, and performing a t-test.\n",
    "\n",
    "**Null Hypothesis (H0):** A statement that there is no effect or no difference, and it is what we seek to test against.\n",
    "\n",
    "**Alternative Hypothesis (H1):** A statement that indicates the presence of an effect or a difference.\n",
    "\n",
    "**P-value:** The probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis is true. A low p-value (typically < 0.05) indicates strong evidence against the null hypothesis, so we reject the null hypothesis.\n",
    "\n",
    "**T-test:** A statistical test used to determine whether there is a significant difference between the means of two groups. In this cell, we perform a one-sample t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Sample Data\n",
    "data = [88, 92, 79, 93, 85, 91, 87, 94, 78, 81]\n",
    "# Hypothesis Testing\n",
    "t_stat, p_value = ttest_1samp(data, 85)\n",
    "print(f'T-statistic: {t_stat}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Interpreting the p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('Reject the null hypothesis')\n",
    "else:\n",
    "    print('Fail to reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00f5da",
   "metadata": {},
   "source": [
    "# Cell 4: Correlation and Regression\n",
    "In this cell, we will cover correlation and simple linear regression, including calculating the correlation coefficient and fitting a regression line.\n",
    "\n",
    "**Correlation Coefficient:** A measure of the strength and direction of the relationship between two variables. It ranges from -1 to 1, where 1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no correlation.\n",
    "\n",
    "**Linear Regression:** A method to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. In simple linear regression, we use one independent variable to predict the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Sample Data\n",
    "data = {'Hours Studied': [1, 2, 3, 4, 5], 'Scores': [60, 61, 64, 68, 70]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculating Correlation Coefficient\n",
    "correlation = df.corr().iloc[0, 1]\n",
    "print(f'Correlation Coefficient: {correlation}')\n",
    "\n",
    "# Performing Linear Regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(df['Hours Studied'], df['Scores'])\n",
    "print(f'Slope: {slope}')\n",
    "print(f'Intercept: {intercept}')\n",
    "print(f'R-squared: {r_value**2}')\n",
    "\n",
    "# Plotting the Regression Line\n",
    "sns.regplot(x='Hours Studied', y='Scores', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e7d3e",
   "metadata": {},
   "source": [
    "# Cell 5: Interquartile Range (IQR)\n",
    "In this cell, we will cover the concept of Interquartile Range (IQR).\n",
    "\n",
    "**Interquartile Range (IQR):** A measure of statistical dispersion, or how spread out the data is. It is calculated as the difference between the 75th percentile (Q3) and the 25th percentile (Q1). The IQR is used to identify outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample Data\n",
    "data = [7, 15, 36, 39, 40, 41, 42, 43, 47, 49]\n",
    "# Calculating Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = np.percentile(data, 25)\n",
    "Q3 = np.percentile(data, 75)\n",
    "# Calculating IQR\n",
    "IQR = Q3 - Q1\n",
    "print(f'Q1: {Q1}')\n",
    "print(f'Q3: {Q3}')\n",
    "print(f'IQR: {IQR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea9896",
   "metadata": {},
   "source": [
    "# Cell 6: Z-Score\n",
    "In this cell, we will cover the concept of Z-Score.\n",
    "\n",
    "**Z-Score:** A measure of how many standard deviations a data point is from the mean. It is calculated as the difference between the value and the mean, divided by the standard deviation. Z-Scores are used to identify outliers and understand the position of a value within a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0863f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample Data\n",
    "data = [88, 92, 79, 93, 85, 91, 87, 94, 78, 81]\n",
    "# Calculating Z-Scores\n",
    "z_scores = stats.zscore(data)\n",
    "print('Z-Scores:')\n",
    "print(z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46291f93",
   "metadata": {},
   "source": [
    "# Cell 7: Confidence Intervals\n",
    "In this cell, we will cover the concept of Confidence Intervals.\n",
    "\n",
    "**Confidence Interval:** A range of values that is likely to contain the true population parameter with a certain level of confidence. It is calculated from the sample data and provides an estimate of the uncertainty around the sample estimate. Common confidence levels are 90%, 95%, and 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c74d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample Data\n",
    "data = [88, 92, 79, 93, 85, 91, 87, 94, 78, 81]\n",
    "# Calculating the mean and standard error of the mean (SEM)\n",
    "mean = np.mean(data)\n",
    "sem = stats.sem(data)\n",
    "# Calculating the 95% confidence interval\n",
    "confidence = 0.95\n",
    "h = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
    "confidence_interval = (mean - h, mean + h)\n",
    "print(f'95% Confidence Interval: {confidence_interval}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
